{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83984342-4a56-42de-a94a-992de4bbc5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data as Data\n",
    "import model as Model\n",
    "import argparse\n",
    "import logging\n",
    "import core.logger as Logger\n",
    "import core.metrics as Metrics\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a54ab9-b1e0-4406-9e41-947c4e25fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "class args_standin():\n",
    "    def __init__(self, config, phase, gpu_ids):\n",
    "        self.config = config\n",
    "        self.phase = phase\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.debug = False\n",
    "\n",
    "# args = args_standin('config/mri_tibia.json', 'val', None)\n",
    "args = args_standin('config/mri_condensed_femur.json', 'val', None)\n",
    "\n",
    "\n",
    "opt = Logger.parse(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75133e99-fa8b-4b37-ab68-44244eb2875e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# opt['path']['resume_state'] = 'experiments/sr_ffhq_211103_145403/checkpoint/I160000_E1034'\n",
    "# opt['datasets']['val']['dataroot'] = 'data/datasets/tibia/tester_inputs'\n",
    "\n",
    "opt['path']['resume_state'] = 'experiments/sr_ffhq_211108_120031/checkpoint/I110000_E330'\n",
    "opt['datasets']['val']['dataroot'] = 'data/datasets/condensed_femur/val_96_288'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4455c5ca-d143-4804-9c12-6b2bb670feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = Data.create_dataset(opt['datasets']['val'], 'val')\n",
    "val_loader = Data.create_dataloader(\n",
    "        val_set, opt['datasets']['val'], 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5fdfd2-4a85-4ed6-a637-ef5d585f67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Model.create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30af18c-1b39-4a16-b11f-6f37b18d0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion.set_new_noise_schedule(opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6e6911-60dd-4ee4-acd4-668270ab6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(val_data, model, result_path, scalefactor):\n",
    "    diffusion=model\n",
    "    diffusion.feed_data(val_data)\n",
    "    diffusion.test(continous=False)\n",
    "    visuals = diffusion.get_current_visuals()\n",
    "    sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "    lr_img = np.repeat(np.repeat(lr_img, scalefactor, axis=0), scalefactor, axis=1)\n",
    "    out_img = np.concatenate((hr_img,lr_img,fake_img,sr_img),axis=1)\n",
    "    Metrics.save_img(out_img, '{}.png'.format(result_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2988f118-0f85-4f44-97ef-e0679379249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image_continuous(val_data, model, result_path, scalefactor):\n",
    "    diffusion=model\n",
    "    diffusion.feed_data(val_data)\n",
    "    diffusion.test(continous=True)\n",
    "    visuals = diffusion.get_current_visuals()\n",
    "    sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    srflat = np.concatenate([sr_img[:,:,i] for i in range(len(sr_img[0,0,:]))],axis=1)\n",
    "    Metrics.save_img(srflat, '{}.png'.format(result_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5bdda1-fe45-4aed-a42e-1d522381481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 2000/2000 [02:30<00:00, 13.31it/s]\n",
      "sampling loop time step: 100%|██████████| 2000/2000 [02:29<00:00, 13.42it/s]\n"
     ]
    }
   ],
   "source": [
    "idx = [6,21]#[1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "scalefactor = int(opt['datasets']['train']['r_resolution']/opt['datasets']['train']['l_resolution'])\n",
    "\n",
    "for i,  val_data in enumerate(val_loader):\n",
    "    if i in idx:\n",
    "        test_image_continuous(val_data, diffusion, \"misc/continuousim_{}\".format(i), scalefactor)\n",
    "    elif i > max(idx):\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa2abe8-e51e-44ad-873b-41d9e9819d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 2000/2000 [03:07<00:00, 10.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#idx = [500, 1000, 1500, 2000, 2500, 3000]\n",
    "idx = [17]\n",
    "scalefactor = int(opt['datasets']['train']['r_resolution']/opt['datasets']['train']['l_resolution'])\n",
    "\n",
    "for i,  val_data in enumerate(val_loader):\n",
    "    if i in idx:\n",
    "        test_image(val_data, diffusion, \"misc/testim_128-256_{}_mri_r0\".format(i), scalefactor)\n",
    "    elif i > max(idx): \n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "#     val_data = np.transpose(np.tile(np.squeeze(np.array(val_data['HR'])),(3,1,1)),[1,2,0])\n",
    "#     val_data = -1*val_data\n",
    "#     plt.imshow(val_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e719956-7789-479d-bb58-7a6a7427ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 2000/2000 [02:30<00:00, 13.26it/s]\n",
      "sampling loop time step: 100%|██████████| 2000/2000 [02:30<00:00, 13.26it/s]\n",
      "sampling loop time step: 100%|██████████| 2000/2000 [02:30<00:00, 13.27it/s]\n",
      "sampling loop time step: 100%|██████████| 2000/2000 [02:30<00:00, 13.27it/s]\n",
      "sampling loop time step: 100%|██████████| 2000/2000 [02:24<00:00, 13.83it/s]\n",
      "sampling loop time step: 100%|██████████| 2000/2000 [02:23<00:00, 13.90it/s]\n",
      "sampling loop time step:  77%|███████▋  | 1537/2000 [01:50<00:33, 13.73it/s]"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "current_epoch = opt['path']['resume_state'][-4:]\n",
    "avg_psnr = 0\n",
    "for _,  val_data in enumerate(val_loader):\n",
    "    idx += 1\n",
    "    diffusion.feed_data(val_data)\n",
    "    diffusion.test(continous=False)\n",
    "    visuals = diffusion.get_current_visuals()\n",
    "    sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "    # generation\n",
    "    Metrics.save_img(\n",
    "        hr_img, 'misc/tibia_reps/{}_{}_hr.png'.format(current_epoch, idx))\n",
    "    Metrics.save_img(\n",
    "        sr_img, 'misc/tibia_reps/{}_{}_sr.png'.format(current_epoch, idx))\n",
    "    Metrics.save_img(\n",
    "        lr_img, 'misc/tibia_reps/{}_{}_lr.png'.format(current_epoch, idx))\n",
    "    Metrics.save_img(\n",
    "        fake_img, 'misc/tibia_reps/{}_{}_inf.png'.format(current_epoch, idx))\n",
    "    if len(sr_img.shape) == 3:# this should only activate if the image is 3 channel, if one channel image, no need to transpose\n",
    "        tb_logger.add_image(\n",
    "            'Iter_{}'.format(current_step),\n",
    "            np.transpose(np.concatenate(\n",
    "                (fake_img, sr_img, hr_img), axis=1), [2, 0, 1]),\n",
    "            idx)\n",
    "    else:\n",
    "        Metrics.save_img(np.concatenate(\n",
    "                (fake_img, hr_img, sr_img), axis=1),\n",
    "            'misc/{}_{}.png'.format(current_epoch, idx))\n",
    "\n",
    "    avg_psnr += Metrics.calculate_psnr(\n",
    "        sr_img, hr_img)\n",
    "#     if idx == 3:\n",
    "#         break\n",
    "\n",
    "avg_psnr = avg_psnr / idx\n",
    "print('{}_{}'.format(current_epoch, avg_psnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba008e0-f91f-4699-9013-8ed5478778b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "2\n",
    "3\n",
    "(4)\n",
    "6\n",
    "7\n",
    "9\n",
    "12\n",
    "(14)\n",
    "(15)\n",
    "17\n",
    "(18)\n",
    "22\n",
    "24\n",
    "25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ecff595-012f-4feb-9964-7583d5563e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 2000/2000 [03:06<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_E60_0.1664998063404325\n"
     ]
    }
   ],
   "source": [
    "ixs = [25]\n",
    "idx = 0\n",
    "current_epoch = opt['path']['resume_state'][-4:]\n",
    "avg_psnr = 0\n",
    "# for j in range(1)\n",
    "for _,  val_data in enumerate(val_loader):\n",
    "    idx += 1\n",
    "    if idx not in ixs:\n",
    "        continue\n",
    "    diffusion.feed_data(val_data)\n",
    "    diffusion.test(continous=False)\n",
    "    visuals = diffusion.get_current_visuals()\n",
    "    sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "    # generation\n",
    "    Metrics.save_img(-\n",
    "        hr_img, 'misc/condensed_femur_reps/{}_{}_hr.png'.format(current_epoch, idx))\n",
    "    Metrics.save_img(\n",
    "        sr_img, 'misc/condensed_femur_reps/{}_{}_sr.png'.format(current_epoch, idx))\n",
    "    Metrics.save_img(\n",
    "        lr_img, 'misc/condensed_femur_reps/{}_{}_lr.png'.format(current_epoch, idx))\n",
    "    Metrics.save_img(\n",
    "        fake_img, 'misc/condensed_femur_reps/{}_{}_inf.png'.format(current_epoch, idx))\n",
    "    if len(sr_img.shape) == 3:# this should only activate if the image is 3 channel, if one channel image, no need to transpose\n",
    "        tb_logger.add_image(\n",
    "            'Iter_{}'.format(current_step),\n",
    "            np.transpose(np.concatenate(\n",
    "                (fake_img, sr_img, hr_img), axis=1), [2, 0, 1]),\n",
    "            idx)\n",
    "    else:\n",
    "        Metrics.save_img(np.concatenate(\n",
    "                (fake_img, hr_img, sr_img), axis=1),\n",
    "            'misc/{}_{}.png'.format(current_epoch, idx))\n",
    "\n",
    "    avg_psnr += Metrics.calculate_psnr(\n",
    "        sr_img, hr_img)\n",
    "#     if idx == 3:\n",
    "#         break\n",
    "\n",
    "avg_psnr = avg_psnr / idx\n",
    "print('{}_{}'.format(current_epoch, avg_psnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e68e4-c656-49f7-b1d0-c50071ae0108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
